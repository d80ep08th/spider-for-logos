{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unsigned-recording",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "from scrapy.exporters import CsvItemExporter\n",
    "import csv\n",
    "\n",
    "file = open('websites.csv')\n",
    "csvreader = csv.reader(file)\n",
    "rows = []\n",
    "\n",
    "for row in csvreader:\n",
    "    rows.append(row)\n",
    "    \n",
    "urls = []\n",
    "for row in rows:\n",
    "    new_row = \"\".join(row)\n",
    "    urls.append(new_row)\n",
    "    \n",
    "https = 'https://www.'\n",
    "domains = [https + url for url in urls]\n",
    "len(domains)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governmental-opposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class logo_crawl(scrapy.Spider):\n",
    "    name = \"logo_links\"\n",
    "    start_urls = domains\n",
    "    \n",
    "    \n",
    "    def parse(self, response):\n",
    "        LOGO = response.xpath('//*[@*[contains(., \"logo\")]]')\n",
    "        FAVICO = response.xpath('//*[@*[contains(., \"favico\")]]')\n",
    "        LOGO_SRC = LOGO.xpath('@src')\n",
    "        FAVICO_HREF = FAVICO.xpath('@href')\n",
    "        \n",
    "        for logo in LOGO_SRC.extract():\n",
    "            yield {\n",
    "                'domain_name': response.url,\n",
    "                'logo_link': logo,\n",
    "                'favico': FAVICO_HREF.extract()\n",
    "            }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-carbon",
   "metadata": {},
   "outputs": [],
   "source": [
    "process = CrawlerProcess(settings = {\n",
    "#    'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)',\n",
    "    \"FEEDS\": {\n",
    "            \"domain_logo_favico.csv\": {\n",
    "            \"format\": \"csv\",\n",
    "            'encoding': 'utf8',\n",
    "            'overwrite': True\n",
    "            },\n",
    "    },\n",
    "    \"LOG_LEVEL\": \"INFO\"\n",
    "})\n",
    "process.crawl(logo_crawl)\n",
    "process.start() # the script will block here until all crawling jobs are finished\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
